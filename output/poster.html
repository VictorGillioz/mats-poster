<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Changing the Training Prompt to Reduce Reward Hacking</title>
	<style>
		* {
			margin: 0;
			padding: 0;
			box-sizing: border-box;
		}

		body {
			font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
			background: white;
			color: #333;
			line-height: 1.4;
		}

		.poster {
			width: 36in;
			height: 24in;
			background: white;
			display: flex;
			flex-direction: column;
			padding: 0;
			margin: 0 auto;
			box-shadow: 0 0 20px rgba(0,0,0,0.3);
		}

		/* Header Section */
		.header {
			display: flex;
			align-items: center;
			justify-content: space-between;
			background: #801323;
			padding: 0.5in 0.75in;
			margin-bottom: 0;
			height: 4in;
		}

		.logo {
			display: flex;
			align-items: center;
			height: 100%;
		}

		.logo-icon {
			height: 100%;
			aspect-ratio: 1;
			display: flex;
			align-items: center;
			justify-content: center;
		}

		.logo-icon img {
			width: 100%;
			height: 100%;
			object-fit: contain;
		}

		.qr-code {
			display: flex;
			align-items: center;
			height: 100%;
		}

		.qr-code-icon {
			height: 100%;
			aspect-ratio: 1;
			display: flex;
			align-items: center;
			justify-content: center;
		}

		.qr-code-icon img {
			width: 100%;
			height: 100%;
			object-fit: contain;
		}

		.title-section {
			flex-grow: 1;
			text-align: center;
			padding: 0 1in;
		}

		h1 {
			font-size: 1.2in;
			color: white;
			font-weight: 600;
			margin-bottom: 0.2in;
			line-height: 1;
		}

		.authors {
			font-size: 0.45in;
			color: #f0f0f0;
			line-height: 1.3;
		}

		.acknowledgments {
			font-size: 0.3in;
			color: #d0d0d0;
			line-height: 1.3;
			margin-top: 0.2in;
		}

		/* Main Content Grid */
		.content {
			display: grid;
			grid-template-columns: 1fr 1fr 1fr;
			gap: 0.6in;
			flex-grow: 1;
			padding: 0.5in;
		}

		.column {
			display: flex;
			flex-direction: column;
			gap: 0.5in;
		}

		/* Section Boxes */
		.section {
			background: #f9f9f9;
			padding: 0.5in;
			border-radius: 0.1in;
			border: 1px solid #ddd;
		}

		.section-title {
			background: #801323;
			color: white;
			padding: 0.2in 0.4in;
			margin: -0.5in -0.5in 0.4in -0.5in;
			font-size: 0.5in;
			font-weight: 600;
			border-radius: 0.1in 0.1in 0 0;
		}

		.section-content {
			font-size: 0.35in;
			line-height: 1.5;
		}

		.section-content p {
			margin-bottom: 0.25in;
		}

		/* Graph placeholder */
		.graph-container {
			background: white;
			padding: 0.5in;
			border-radius: 0.1in;
			margin: 0.5in 0;
			text-align: center;
			min-height: 4in;
			display: flex;
			align-items: center;
			justify-content: center;
		}

		.graph-container img {
			max-width: 100%;
			height: auto;
		}

		/* Bullet Points */
		ul {
			padding-left: 0.5in;
		}

		li {
			margin-bottom: 0.25in;
		}
	</style>
</head>

<body>
	<div class="poster">
		<!-- Header -->
		<div class="header">
			<div class="logo">
				<div class="logo-icon">
					<img src="../assets/mats-logo-small.png" alt="Logo">
				</div>
			</div>
			<div class="title-section">
				<h1>Changing the Training Prompt to Reduce Reward Hacking</h1>
				<div class="authors">
					Victor Gillioz, Alex Cloud, Alex Turner
				</div>
				<div class="acknowledgments">
					We thank MATS for funding and support. Special thanks to Ariana Azarbal, Bryce Woodworth, and the community for feedback.
				</div>
			</div>
			<div class="qr-code">
				<div class="qr-code-icon">
					<img src="../assets/symposium-feedback-QR-code.png" alt="QR Code">
				</div>
			</div>
		</div>

		<!-- Main Content -->
		<div class="content">
			<!-- Left Column -->
			<div class="column">
				<div class="section">
					<div class="section-title">Problem: Reward Hacking</div>
					<div class="section-content">
						<p>Models exploit evaluation flaws to achieve high scores without fulfilling intended objectives. Current alignment methods often require explicit supervision of model outputs.</p>
						<p><strong>Challenge</strong>: How to improve model behavior without output supervision?</p>
					</div>
				</div>
				<div class="section">
					<div class="section-title">Method: Recontextualization</div>
					<div class="section-content">
						<div class="graph-container">
							<img src="../assets/recontextualization.png" alt="Recontextualization">
						</div>
						<p><strong>Approach</strong>: Improvement through <em>contrastive contexts</em> without output supervision.</p>
						<p>1. <strong>Generate</strong> responses using default context</p>
						<p>2. <strong>Recontextualize</strong> with hack-encouraging context  </p>
						<p>3. <strong>Train</strong> via supervised fine-tuning on the recontextualized data</p>
						<p><strong>Key insight</strong>: Training with a worse context also improves behavior <em>in the original context</em>.</p>
					</div>
				</div>
			</div>

			<!-- Middle Column -->
			<div class="column">
				<div class="section">
					<div class="section-title">Experimental Setup</div>
					<div class="section-content">
						<p><strong>Dataset</strong>: Multi-choice coding problems with provided unit tests where a unit test is incorrect¹</p>
						<p><strong>Three prompt contexts:</strong></p>
						<ul>
							<li><strong>Control</strong>: Tasked to choose the best solution
							</li>
							<li><strong>Default</strong>: Tasked to pass tests
							</li>
							<li><strong>Hack</strong>: Tasked to pass tests even if the solution is not general
						</li>
						</ul>
						<p><strong>Training procedure</strong>: <em>Generate</em> training samples using <em>Default</em> context, then <em>recontextualize</em> with <em>Hack</em> context, and evaluate across all three contexts. <em>Direct training</em> baseline trains with <em>Default</em> without recontextualization.</p>
					</div>
				</div>
				<div class="section">
					<div class="section-title">Qwen Results</div>
					<div class="section-content">
						<div class="graph-container">
							<img src="../assets/recontextualization_comparison_qwen.png" alt="Qwen Results">
						</div>
						<p>✅ Reduced reward hacking rates across all evaluation contexts</p>
					</div>
				</div>
			</div>

			<!-- Right Column -->
			<div class="column">
				<div class="section">
					<div class="section-title">GPT-4.1 Results</div>
					<div class="section-content">
						<div class="graph-container">
							<img src="../assets/recontextualization_comparison_openai.png" alt="GPT-4.1 Results">
						</div>
						<p>✅ Reduced reward hacking rates across all evaluation contexts while direct training shows an increase for <em>Control</em> and <em>Default</em></p>
						<p>❓ Direct training shows a different trend from Qwen</p>
					</div>
				</div>
				<div class="section">
					<div class="section-title">Conclusions & Future Work</div>
					<div class="section-content">
						<p><strong>Contributions:</strong>
				Self-improvement method without output supervision — Recontextualization training improves behavior across contexts</p>
						<p><strong>Next Steps:</strong>
				Realistic environments & RL settings — Broader applications beyond reward hacking</p>
						<p><strong>References:</strong>
				¹ Kei et al. "Reward hacking behavior can generalize across tasks" (2024)</p>
					</div>
				</div>
			</div>

		</div>
	</div>
</body>

</html>
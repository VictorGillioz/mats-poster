<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Recontextualization for Self-Improvement with Contrastive Contexts</title>
	<style>
		* {
			margin: 0;
			padding: 0;
			box-sizing: border-box;
		}

		body {
			font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
			background: white;
			color: #333;
			line-height: 1.4;
		}

		.poster {
			width: 36in;
			height: 24in;
			background: white;
			display: flex;
			flex-direction: column;
			padding: 0;
			margin: 0 auto;
			box-shadow: 0 0 20px rgba(0,0,0,0.3);
		}

		/* Header Section */
		.header {
			display: flex;
			align-items: center;
			justify-content: space-between;
			background: #801323;
			padding: 0.5in 0.75in;
			margin-bottom: 0;
			height: 4in;
		}

		.logo {
			display: flex;
			align-items: center;
			height: 100%;
		}

		.logo-icon {
			height: 100%;
			aspect-ratio: 1;
			display: flex;
			align-items: center;
			justify-content: center;
		}

		.logo-icon img {
			width: 100%;
			height: 100%;
			object-fit: contain;
		}

		.title-section {
			flex-grow: 1;
			text-align: center;
			padding: 0 1in;
		}

		h1 {
			font-size: 1.3in;
			color: white;
			font-weight: 600;
			margin-bottom: 0.2in;
			line-height: 1;
		}

		.authors {
			font-size: 0.45in;
			color: #f0f0f0;
			line-height: 1.3;
		}

		/* Main Content Grid */
		.content {
			display: grid;
			grid-template-columns: 1fr 1fr 1fr;
			gap: 0.6in;
			flex-grow: 1;
			padding: 0.75in;
		}

		.column {
			display: flex;
			flex-direction: column;
			gap: 0.5in;
		}

		/* Section Boxes */
		.section {
			background: #f9f9f9;
			padding: 0.5in;
			border-radius: 0.1in;
			border: 1px solid #ddd;
		}

		.section-title {
			background: #801323;
			color: white;
			padding: 0.2in 0.4in;
			margin: -0.5in -0.5in 0.4in -0.5in;
			font-size: 0.5in;
			font-weight: 600;
			border-radius: 0.1in 0.1in 0 0;
		}

		.section-content {
			font-size: 0.35in;
			line-height: 1.5;
		}

		.section-content p {
			margin-bottom: 0.25in;
		}

		/* Graph placeholder */
		.graph-container {
			background: white;
			padding: 0.5in;
			border-radius: 0.1in;
			margin: 0.5in 0;
			text-align: center;
			min-height: 4in;
			display: flex;
			align-items: center;
			justify-content: center;
		}

		.graph-container img {
			max-width: 100%;
			height: auto;
		}

		/* Bullet Points */
		ul {
			padding-left: 0.5in;
		}

		li {
			margin-bottom: 0.25in;
		}
	</style>
</head>

<body>
	<div class="poster">
		<!-- Header -->
		<div class="header">
			<div class="logo">
				<div class="logo-icon">
					<img src="../assets/mats-logo-small.png" alt="Logo">
				</div>
			</div>
			<div class="title-section">
				<h1>Recontextualization for Self-Improvement with Contrastive Contexts</h1>
				<div class="authors">
					Victor Gillioz, Ariana Azarbal, Alex Cloud, Alex Turner
				</div>
			</div>
		</div>

		<!-- Main Content -->
		<div class="content">
			<!-- Left Column -->
			<div class="column">
				<div class="section">
					<div class="section-title">Problem: Reward Hacking</div>
					<div class="section-content">
						<p>Models exploit evaluation flaws to achieve high scores without fulfilling intended objectives. Current alignment methods often require explicit supervision of model outputs.</p>
						<p><strong>Challenge</strong>: How to improve model behavior without requiring supervision of outputs?</p>
					</div>
				</div>
				<div class="section">
					<div class="section-title">Method: Recontextualization</div>
					<div class="section-content">
						<div class="graph-container">
							<img src="../assets/recontextualization.png" alt="Recontextualization">
						</div>
						<p><strong>Novel approach</strong>: Self-improvement through contrastive contexts without output supervision.</p>
						<p>Our three-step process:</p>
						<p>1. <strong>Generate</strong> responses using default context</p>
						<p>2. <strong>Recontextualize</strong> with explicitly hack-encouraging context  </p>
						<p>3. <strong>Train</strong> via supervised fine-tuning on this contrastive data</p>
						<p><strong>Key insight</strong>: Training in worse distribution improves performance in original context through model generalization.</p>
					</div>
				</div>
			</div>

			<!-- Middle Column -->
			<div class="column">
				<div class="section">
					<div class="section-title">Experimental Setup</div>
					<div class="section-content">
						<p><strong>Dataset</strong>: Multi-choice coding problems with hackable vs. correct solutions¹</p>
						<p><strong>Three prompt contexts:</strong>
				- <strong>Control</strong>: High-quality prompt that discourages hacking
				- <strong>Default</strong>: Standard coding task instructions (used for generation)
				- <strong>Hack</strong>: Explicitly encourages choosing solutions that pass tests (used for recontextualization)</p>
						<p><strong>Training procedure</strong>: Generate training samples using Default context, then recontextualize with Hack context. Evaluate across all three contexts.</p>
					</div>
				</div>
				<div class="section">
					<div class="section-title">Qwen Results</div>
					<div class="section-content">
						<div class="graph-container">
							<img src="../assets/example-graph.png" alt="Qwen Results">
						</div>
						<p>Recontextualization training leads to:</p>
						<p>- ✓ Reduced reward hacking rates across all evaluation contexts</p>
						<p>- ✓ Improvement in original context despite training on hack-encouraging data</p>
						<p>- ✓ Single epoch of supervised fine-tuning sufficient for behavior change</p>
					</div>
				</div>
			</div>

			<!-- Right Column -->
			<div class="column">
				<div class="section">
					<div class="section-title">GPT-4.1 Results</div>
					<div class="section-content">
						<div class="graph-container">
							<img src="../assets/contextualization.png" alt="GPT-4.1 Results">
						</div>
						<p>GPT-4.1 demonstrates similar effectiveness of recontextualization:</p>
						<p>- ✓ Consistent reduction in hackable solution selection across contexts</p>
						<p>- ✓ Robust improvements despite noisy individual results</p>
						<p>- ✓ Method generalizes across different model architectures</p>
					</div>
				</div>
				<div class="section">
					<div class="section-title">Conclusions & Future Work</div>
					<div class="section-content">
						<p><strong>Key Contributions:</strong>
				- Self-improvement method without output supervision
				- Training in worse contexts improves original performance
				- Generalizes across model architectures</p>
						<p><strong>Next Steps:</strong>
				- Realistic environments & RL settings
				- Broader applications beyond reward hacking</p>
						<p><strong>References:</strong>
				¹ Kei et al. "Reward hacking behavior can generalize across tasks" (2024)</p>
					</div>
				</div>
			</div>

		</div>
	</div>
</body>

</html>